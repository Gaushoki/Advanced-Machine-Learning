{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tr9o4rl9fUBh"
   },
   "source": [
    "<img src = \"images/Logo.png\" width = 220, align = \"left\">\n",
    "\n",
    "<h1 align=center><font size = 6><span style=\"color:blue\">Imputation</span></font></h1>\n",
    "<h2 align=center><font size = 5>Lab Exercise 3.9</font></h2>\n",
    "<h3 align=center><font size = 4><b>Advanced Machine Learning Made Easy<br></b><small>From Theory to Practice with NumPy and scikit-learn<br><i>Volume 1: Generalized Linear Models</i></font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In practical data science, datasets are incomplete or may contain erroneous data. For this reason, a way of handle missing data is a must before a machine learning algorithm is deployed. One way to handle missing data is to either delete multiple observations (samples, which have at least one missing value) or an entire feature (if that feature may contain more than 25-30% of missing values). However, deletion shall be seen as information loss and shall be avoided. Instead, in most cases, it is better to guess the missing data. This kind of process is called imputation. In this lab exercise, different imputation methods are analyzed and compared. \n",
    "\n",
    "**Note:** *In this lab exercise, we will use another dataset related to houses prices will be used, contained in the scikit-learn library.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "1. [Preparation](#Preparation)\n",
    "2. [Deletion method](#Deletion)\n",
    "3. [Simple imputation](#Simple)\n",
    "4. [k-NN imputation](#k-NN)\n",
    "5. [Linear regression imputation](#Linear)\n",
    "6. [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation <a name=\"Preparation\"></a>\n",
    "\n",
    "Before moving on, as a first step, we import the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fs6Gm5gtexW9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUZRG9jlf0A4"
   },
   "source": [
    "To have a broader view, let's use another dataset regarding house prices which is part of the scikit-learn library database. \n",
    "As a first step, let's read the dataset into a pandas dataframe. Then we may print out the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "data=fetch_california_housing(as_frame=True)\n",
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, all the features are numerical. <br>\n",
    "We may also check the name of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedHouseVal']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., the target is the median house value in that block. We may also print out the values of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.526\n",
       "1        3.585\n",
       "2        3.521\n",
       "3        3.413\n",
       "4        3.422\n",
       "         ...  \n",
       "20635    0.781\n",
       "20636    0.771\n",
       "20637    0.923\n",
       "20638    0.847\n",
       "20639    0.894\n",
       "Name: MedHouseVal, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our complete dataframe, including the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data['MedHouseVal']=data.target\n",
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decrease the typing effort when creating the statsmodels formula, let's create the following variable containing all the features with the addition symbol in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MedInc + HouseAge + AveRooms + AveBedrms + Population + AveOccup + Latitude + Longitude'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addfeature=list(data.data.columns)\n",
    "addfeature.remove('MedHouseVal')\n",
    "addfeature=' + '.join(addfeature)\n",
    "addfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the OLS results, but using mean squared error at this time to not confuse with the RMSE scoring function defined between the original and imputed data (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     OLS results for the original dataset                     \n",
      "==============================================================================\n",
      "Dep. Variable:            MedHouseVal   R-squared:                       0.606\n",
      "Model:                            OLS   Adj. R-squared:                  0.606\n",
      "Method:                 Least Squares   F-statistic:                     3970.\n",
      "Date:                Thu, 29 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        15:12:53   Log-Likelihood:                -22624.\n",
      "No. Observations:               20640   AIC:                         4.527e+04\n",
      "Df Residuals:                   20631   BIC:                         4.534e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -36.9419      0.659    -56.067      0.000     -38.233     -35.650\n",
      "MedInc         0.4367      0.004    104.054      0.000       0.428       0.445\n",
      "HouseAge       0.0094      0.000     21.143      0.000       0.009       0.010\n",
      "AveRooms      -0.1073      0.006    -18.235      0.000      -0.119      -0.096\n",
      "AveBedrms      0.6451      0.028     22.928      0.000       0.590       0.700\n",
      "Population -3.976e-06   4.75e-06     -0.837      0.402   -1.33e-05    5.33e-06\n",
      "AveOccup      -0.0038      0.000     -7.769      0.000      -0.005      -0.003\n",
      "Latitude      -0.4213      0.007    -58.541      0.000      -0.435      -0.407\n",
      "Longitude     -0.4345      0.008    -57.682      0.000      -0.449      -0.420\n",
      "==============================================================================\n",
      "Omnibus:                     4393.650   Durbin-Watson:                   0.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14087.596\n",
      "Skew:                           1.082   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.420   Cond. No.                     2.38e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.38e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "MSE = 0.5245497142576847\n"
     ]
    }
   ],
   "source": [
    "model = ols(formula = 'MedHouseVal ~ ' + addfeature, data=data.data).fit()\n",
    "print(model.summary(title=\"OLS results for the original dataset\"))\n",
    "print(\"\\nMSE =\",model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, there is no statistical evidence that the \"Population\" input variable has a coefficient different from zero according to the p-value. Let's remove it from the OLS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OLS results for the original dataset with 'Population' feature removed    \n",
      "==============================================================================\n",
      "Dep. Variable:            MedHouseVal   R-squared:                       0.606\n",
      "Model:                            OLS   Adj. R-squared:                  0.606\n",
      "Method:                 Least Squares   F-statistic:                     4538.\n",
      "Date:                Thu, 29 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        15:12:53   Log-Likelihood:                -22624.\n",
      "No. Observations:               20640   AIC:                         4.526e+04\n",
      "Df Residuals:                   20632   BIC:                         4.533e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -36.9175      0.658    -56.085      0.000     -38.208     -35.627\n",
      "MedInc         0.4368      0.004    104.089      0.000       0.429       0.445\n",
      "HouseAge       0.0096      0.000     22.602      0.000       0.009       0.010\n",
      "AveRooms      -0.1071      0.006    -18.217      0.000      -0.119      -0.096\n",
      "AveBedrms      0.6449      0.028     22.922      0.000       0.590       0.700\n",
      "AveOccup      -0.0038      0.000     -7.861      0.000      -0.005      -0.003\n",
      "Latitude      -0.4207      0.007    -58.763      0.000      -0.435      -0.407\n",
      "Longitude     -0.4340      0.008    -57.782      0.000      -0.449      -0.419\n",
      "==============================================================================\n",
      "Omnibus:                     4406.193   Durbin-Watson:                   0.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14155.786\n",
      "Skew:                           1.084   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.429   Cond. No.                     1.68e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.68e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "MSE = 0.5245421132432017\n"
     ]
    }
   ],
   "source": [
    "addfeature=list(data.data.columns)\n",
    "addfeature.remove('Population')\n",
    "addfeature.remove('MedHouseVal')\n",
    "addfeature=' + '.join(addfeature)\n",
    "addfeature\n",
    "model = ols(formula = 'MedHouseVal ~ ' + addfeature, data=data.data).fit()\n",
    "print(model.summary(title=\"OLS results for the original dataset with 'Population' feature removed\"))\n",
    "print(\"\\nMSE =\",model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditioning number is still very high, indicating numerical instability. Let's center the data to see if that would help to solve the numerical instability problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(data.data.columns)\n",
    "features.remove('MedHouseVal')\n",
    "data_o=data.data[features].apply(lambda x: x-x.mean())\n",
    "data_o['MedHouseVal']=data.data['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then print out the OLS results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OLS results for the centered dataset with 'Population' feature removed    \n",
      "==============================================================================\n",
      "Dep. Variable:            MedHouseVal   R-squared:                       0.606\n",
      "Model:                            OLS   Adj. R-squared:                  0.606\n",
      "Method:                 Least Squares   F-statistic:                     4538.\n",
      "Date:                Thu, 29 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        15:12:53   Log-Likelihood:                -22624.\n",
      "No. Observations:               20640   AIC:                         4.526e+04\n",
      "Df Residuals:                   20632   BIC:                         4.533e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.0686      0.005    410.329      0.000       2.059       2.078\n",
      "MedInc         0.4368      0.004    104.089      0.000       0.429       0.445\n",
      "HouseAge       0.0096      0.000     22.602      0.000       0.009       0.010\n",
      "AveRooms      -0.1071      0.006    -18.217      0.000      -0.119      -0.096\n",
      "AveBedrms      0.6449      0.028     22.922      0.000       0.590       0.700\n",
      "AveOccup      -0.0038      0.000     -7.861      0.000      -0.005      -0.003\n",
      "Latitude      -0.4207      0.007    -58.763      0.000      -0.435      -0.407\n",
      "Longitude     -0.4340      0.008    -57.782      0.000      -0.449      -0.419\n",
      "==============================================================================\n",
      "Omnibus:                     4406.193   Durbin-Watson:                   0.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14155.786\n",
      "Skew:                           1.084   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.429   Cond. No.                         72.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "MSE = 0.5245421132432019\n"
     ]
    }
   ],
   "source": [
    "model = ols(formula = 'MedHouseVal ~ ' + addfeature, data=data_o).fit()\n",
    "print(model.summary(title=\"OLS results for the centered dataset with 'Population' feature removed\"))\n",
    "print(\"\\nMSE =\",model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, neither the R-squared value nor the MSE was affected by these changes, so in what follows, we will use the original dataset.\n",
    "\n",
    "Let's create a copy of the input data and add completely random NaN values to the data. Half of the observation will be affected (i.e., half of the observation will contain one feature or the target with a NaN value). That corresponds to the missing completely at random (MCAR) use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy=np.array(data.data)\n",
    "N,D=Xy.shape\n",
    "miss_rate=0.5\n",
    "miss_obs_nr=int(N*miss_rate)\n",
    "mask=np.zeros(N, dtype=bool)\n",
    "mask[:miss_obs_nr] = True\n",
    "np.random.shuffle(mask)\n",
    "miss_feature=np.random.randint(0, D, miss_obs_nr)\n",
    "Xy_miss=Xy.copy()\n",
    "Xy_miss[mask, miss_feature] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may check the total number of NaN values in the input data, including the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10320"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(Xy_miss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the RMSE scoring function to evaluate and compare the different imputation methods. <br>\n",
    "**Note:** *This shall not be confused with the RMSE value of the OLS.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(Xy_full, Xy_imp,mask):\n",
    "    N_miss=np.array(mask[0]).sum() # nr of imputed element is the sum of True values in the mask of obs.\n",
    "    return np.sqrt(np.sum((Xy_full[mask[0],mask[1]]-Xy_imp[mask[0],mask[1]])**2)/N_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deletion method <a name=\"Deletion\"></a>\n",
    "\n",
    "One way to solve the missing value problem is to delete the entire sample (row) from the dataset if at least one missing value is present, either in the input or the output. However, that would result in information loss as half of the dataset would be gone to the garbage in our case.\n",
    "\n",
    "Let's create a new dataset, where the completely random missing values are discarded, i.e., around half of the dataset is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[]\n",
    "for i in range(Xy_miss.shape[0]):\n",
    "    if np.sum(np.isnan(Xy_miss[i,:])):\n",
    "        idx.append(i)\n",
    "Xy_del=np.delete(Xy_miss,idx,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the new dataset contains NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(Xy_del))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, after deletion, there are no NaN values present in the dataset. Now create the new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1200</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.797527</td>\n",
       "      <td>1.061824</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>1.788253</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>2.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2031</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.477612</td>\n",
       "      <td>1.079602</td>\n",
       "      <td>910.0</td>\n",
       "      <td>2.263682</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>2.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0750</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.322650</td>\n",
       "      <td>1.012821</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>2.346154</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>2.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315</th>\n",
       "      <td>3.5673</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.932584</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>2.824719</td>\n",
       "      <td>39.29</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>1.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>3.1250</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.023377</td>\n",
       "      <td>1.080519</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>2.719481</td>\n",
       "      <td>39.26</td>\n",
       "      <td>-121.45</td>\n",
       "      <td>1.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>3.7125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.779070</td>\n",
       "      <td>1.148256</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>3.026163</td>\n",
       "      <td>39.27</td>\n",
       "      <td>-121.56</td>\n",
       "      <td>1.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10318</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "1      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "2      3.1200      52.0  4.797527   1.061824      1157.0  1.788253     37.84   \n",
       "3      3.2031      52.0  5.477612   1.079602       910.0  2.263682     37.85   \n",
       "4      3.0750      52.0  5.322650   1.012821      1098.0  2.346154     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "10315  3.5673      11.0  5.932584   1.134831      1257.0  2.824719     39.29   \n",
       "10316  3.1250      15.0  6.023377   1.080519      1047.0  2.719481     39.26   \n",
       "10317  3.7125      28.0  6.779070   1.148256      1041.0  3.026163     39.27   \n",
       "10318  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "10319  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.24        3.521  \n",
       "1        -122.25        3.413  \n",
       "2        -122.25        2.414  \n",
       "3        -122.26        2.815  \n",
       "4        -122.26        2.135  \n",
       "...          ...          ...  \n",
       "10315    -121.32        1.120  \n",
       "10316    -121.45        1.156  \n",
       "10317    -121.56        1.168  \n",
       "10318    -121.09        0.781  \n",
       "10319    -121.21        0.771  \n",
       "\n",
       "[10320 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=list(data.data.columns)\n",
    "data_del=pd.DataFrame(data=Xy_del,columns=features)\n",
    "data_del"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then print out the OLS results for the half-deleted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   OLS results for the half-deleted dataset                   \n",
      "==============================================================================\n",
      "Dep. Variable:            MedHouseVal   R-squared:                       0.610\n",
      "Model:                            OLS   Adj. R-squared:                  0.610\n",
      "Method:                 Least Squares   F-statistic:                     2302.\n",
      "Date:                Thu, 29 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        15:12:54   Log-Likelihood:                -11175.\n",
      "No. Observations:               10320   AIC:                         2.237e+04\n",
      "Df Residuals:                   10312   BIC:                         2.242e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -37.7815      0.916    -41.242      0.000     -39.577     -35.986\n",
      "MedInc         0.4283      0.006     74.532      0.000       0.417       0.440\n",
      "HouseAge       0.0093      0.001     15.701      0.000       0.008       0.010\n",
      "AveRooms      -0.0934      0.008    -11.790      0.000      -0.109      -0.078\n",
      "AveBedrms      0.5776      0.038     15.320      0.000       0.504       0.652\n",
      "AveOccup      -0.0041      0.001     -7.139      0.000      -0.005      -0.003\n",
      "Latitude      -0.4254      0.010    -42.980      0.000      -0.445      -0.406\n",
      "Longitude     -0.4430      0.010    -42.433      0.000      -0.463      -0.423\n",
      "==============================================================================\n",
      "Omnibus:                     2276.217   Durbin-Watson:                   0.972\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8530.963\n",
      "Skew:                           1.066   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.910   Cond. No.                     1.67e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.67e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "MSE = 0.5109686825556595\n"
     ]
    }
   ],
   "source": [
    "model = ols(formula = 'MedHouseVal ~ ' + addfeature, data=data_del).fit()\n",
    "print(model.summary(title=\"OLS results for the half-deleted dataset\"))\n",
    "print(\"\\nMSE =\",model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, for this particular dataset, randomly removing half of the observations will not affect the linear regression model as the goodness of fit is only slightly changed. However, this is not the case for other datasets or other types of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple imputation <a name=\"Simple\"></a>\n",
    "\n",
    "Missing values can be imputed with a provided constant value, like 0, or using the statistics - like mean, median, or most frequent - of each feature in which the missing values are located.\n",
    "\n",
    "Let's impute the missing values first with a constant value of 0 and then calculate the RMSE scoring function between the original and imputed dataset (i.e., calculate the root mean square error between the two datasets -  the lower the RMSE value, the greater the match between the two datasets). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 717.8887660641294\n"
     ]
    }
   ],
   "source": [
    "rmse_vals=[]\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=0)\n",
    "Xy_impute=simple_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also use the mean of each feature/target as the imputation method for missing values (i.e., the average value of a feature to be used to fill the missing value(s) for that feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 519.0136146307217\n"
     ]
    }
   ],
   "source": [
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Xy_impute=simple_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When outliers are present, the median of each feature/target should be used for the imputation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 529.0446814224471\n"
     ]
    }
   ],
   "source": [
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "Xy_impute=simple_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical features, only the most frequent values can be used as a simple imputation method. That imputation can be also used for numerical features/target, also called simple imputation with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 571.5800218540074\n"
     ]
    }
   ],
   "source": [
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "Xy_impute=simple_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the obtained RMSE score values in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Constant (zero)</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Most frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>717.888766</td>\n",
       "      <td>519.013615</td>\n",
       "      <td>529.044681</td>\n",
       "      <td>571.580022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Constant (zero)        Mean      Median  Most frequent\n",
       "RMSE       717.888766  519.013615  529.044681     571.580022"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=np.array(rmse_vals)[np.newaxis],columns=['Constant (zero)','Mean','Median','Most frequent'],index=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These RMSE values might be slightly different from the ones presented in the book. That is because of the random nature of the deletion of the values from the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. k-NN imputation <a name=\"k-NN\"></a>\n",
    "\n",
    "The problem with this kind of simple imputation, like mean, median, or mode, is that it does not account for the distribution of the data. It may also affect the existing correlation between the features and the target, which a linear model is based on. Moreover, the problem with the constant imputation is that, for some features, this might not even make sense (for example, setting zero for the average number of rooms for a house price prediction).\n",
    "\n",
    "Due to the limitation of simple imputation methods described above, another approach, called kNN imputing, can be used for filling missing data. kNN imputing method is based on the k-nearest neighbor's algorithm. In this procedure, first, we locate the observation with at least one missing value. Then we identify the \"k\" number of most similar observations (neighbors) in the (training) data that are complete (i.e., have no missing values in any column). The similarity of the observations is defined by a distance metric, like Euclidean distance. After computing the distances, the \"k\" closest observations to the sample in question are identified, and the average value of the predictor of interest is calculated to be used for imputation (weighted average is also possible, where the weights are inversely proportional with the distance). In the case of the scikit-learn library the number of the neighbors, as well as the type of average calculation shall be provided (i.e. 'uniform' when all k neighbors are treated equally, or 'distance' when the weighted average is calculated, where the weights are inversely proportional with the distance).\n",
    "\n",
    "Let's first set the number of neighbors to a minimum of 3 with uniform wights. <br>\n",
    "**Note:** *The following code might take a couple of 10 seconds to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 514.1443652683315\n"
     ]
    }
   ],
   "source": [
    "rmse_vals=[]\n",
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=3,weights='uniform')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's increase the number of neighbors to five. The number of neighbors shall be set always to an odd number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 498.1538870340367\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=5,weights='uniform')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the more neighbors are taken into account during imputation, the better the obtained results would be. So let's increase the number of neighbors to seven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 495.66701333938573\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=7,weights='uniform')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's increase the number of neighbors to nine. (Rarely makes sense to go beyond that value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 494.5207850064802\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=9,weights='uniform')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we change the imputation to the weighted average. Again, let's start with k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 512.1430162734681\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=3,weights='distance')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then increase the number of neighbors to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 497.2494610802614\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=5,weights='distance')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, again change the number of neighbors to seven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 494.4897358596639\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=7,weights='distance')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, set the number of neighbors to nine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 492.78434259071946\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=9,weights='distance')\n",
    "Xy_impute=knn_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the obtained RMSE scoring values in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbors=3</th>\n",
       "      <th>neighbors=5</th>\n",
       "      <th>neighbors=7</th>\n",
       "      <th>neighbors=9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE (uniform weight)</th>\n",
       "      <td>514.144365</td>\n",
       "      <td>498.153887</td>\n",
       "      <td>495.667013</td>\n",
       "      <td>494.520785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (distance weight)</th>\n",
       "      <td>512.143016</td>\n",
       "      <td>497.249461</td>\n",
       "      <td>494.489736</td>\n",
       "      <td>492.784343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        neighbors=3  neighbors=5  neighbors=7  neighbors=9\n",
       "RMSE (uniform weight)    514.144365   498.153887   495.667013   494.520785\n",
       "RMSE (distance weight)   512.143016   497.249461   494.489736   492.784343"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=np.array(rmse_vals).reshape((2,4)),columns=['neighbors=3','neighbors=5','neighbors=7','neighbors=9'],\\\n",
    "             index=['RMSE (uniform weight)','RMSE (distance weight)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear regression imputation <a name=\"Linear\"></a>\n",
    "\n",
    "When one or several predictors without missing values show a strong linear relationship with a predictor that requires imputation, a straightforward linear model may be the best approach. Of course, such an imputation method is appropriate only for non-linear machine learning algorithms discussed in the other two volumes of this book series. \n",
    "\n",
    "The scikit-learn library provides an experimental iterative imputation method that can handle several types of estimators, including linear regression. Other regression types, like regression based on k-nearest neighbors or decision tree regression discussed in the second volume of the book series, may also be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 494.24816357082454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "rmse_vals=[]\n",
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=LinearRegression())\n",
    "Xy_impute=iterative_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other forms of regression discussed in volume two of the book series may be considered. One is the k-NN regressor. Let's use a k-NN regressor with k=7 and uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 474.22239455668006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=KNeighborsRegressor(n_neighbors=7, weights='uniform'))\n",
    "Xy_impute=iterative_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also try a k-NN regressor with a weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 474.95259045315146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=KNeighborsRegressor(n_neighbors=7, weights='distance'))\n",
    "Xy_impute=iterative_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try the decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 514.8945162753422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=DecisionTreeRegressor())\n",
    "Xy_impute=iterative_imputer.fit_transform(Xy_miss)\n",
    "rmse=RMSE(Xy,Xy_impute,[mask, miss_feature])\n",
    "rmse_vals.append(rmse)\n",
    "print(\"RMSE =\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the obtained RMSE score values in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>kNN (uniform)</th>\n",
       "      <th>kNN (weighted)</th>\n",
       "      <th>Decision tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>494.248164</td>\n",
       "      <td>474.222395</td>\n",
       "      <td>474.95259</td>\n",
       "      <td>514.894516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Linear  kNN (uniform)  kNN (weighted)  Decision tree\n",
       "RMSE  494.248164     474.222395       474.95259     514.894516"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=np.array(rmse_vals)[np.newaxis],columns=['Linear','kNN (uniform)','kNN (weighted)','Decision tree'],\\\n",
    "             index=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary <a name=\"Summary\"></a>\n",
    "\n",
    "Until now, we considered only the RMSE as a scoring value to compare different imputation methods. But we may also use the R-squared and mean squared error of the OLS applied on the imputed dataset.\n",
    "\n",
    "Let's calculate the goodness of fit of a linear model on the original dataset. We store the goodness of fit values in two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.606\n",
      "MSE = 0.524\n"
     ]
    }
   ],
   "source": [
    "R2=[]\n",
    "MSE=[]\n",
    "names=[]\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "X,y=fetch_california_housing(return_X_y=True)\n",
    "linregr=LinearRegression()\n",
    "linregr.fit(X,y)\n",
    "R2_val=r2_score(y,linregr.predict(X))\n",
    "MSE_val=mean_squared_error(y,linregr.predict(X))\n",
    "print(\"R2 = %1.3f\"%(R2_val))\n",
    "print(\"MSE = %1.3f\"%(MSE_val))\n",
    "R2.append(R2_val)\n",
    "MSE.append(MSE_val)\n",
    "names.append('Original data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, remove feature values completely at random from half of the observations. Because we will use the pipeline at this time, the target values are not removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D=X.shape\n",
    "miss_rate=0.5\n",
    "miss_obs_nr=int(N*miss_rate)\n",
    "mask=np.zeros(N, dtype=bool)\n",
    "mask[:miss_obs_nr] = True\n",
    "np.random.shuffle(mask)\n",
    "miss_feature=np.random.randint(0, D, miss_obs_nr)\n",
    "X_miss=X.copy()\n",
    "X_miss[mask, miss_feature] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using a constant value of 0 for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.380\n",
      "MSE = 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=0)\n",
    "pipe=Pipeline(steps=[('preproc',simple_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('Simple imputer (constant)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the mean value for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.529\n",
      "MSE = 0.627\n"
     ]
    }
   ],
   "source": [
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "pipe=Pipeline(steps=[('preproc',simple_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('Simple imputer (mean)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the median value for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.519\n",
      "MSE = 0.640\n"
     ]
    }
   ],
   "source": [
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "pipe=Pipeline(steps=[('preproc',simple_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('Simple imputer (median)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the mode value for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.284\n",
      "MSE = 0.953\n"
     ]
    }
   ],
   "source": [
    "simple_imputer=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "pipe=Pipeline(steps=[('preproc',simple_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('Simple imputer (mode)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the kNN imputation with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.584\n",
      "MSE = 0.554\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=7,weights='uniform')\n",
    "pipe=Pipeline(steps=[('preproc',knn_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "yhat=pipe.predict(X_miss)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,yhat)))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,yhat)))\n",
    "R2.append(r2_score(y,yhat))\n",
    "MSE.append(mean_squared_error(y,yhat))\n",
    "names.append('kNN imputer (uniform)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the kNN imputation with a weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.585\n",
      "MSE = 0.552\n"
     ]
    }
   ],
   "source": [
    "knn_imputer=KNNImputer(missing_values=np.nan, n_neighbors=7,weights='distance')\n",
    "pipe=Pipeline(steps=[('preproc',knn_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "yhat=pipe.predict(X_miss)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,yhat)))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,yhat)))\n",
    "R2.append(r2_score(y,yhat))\n",
    "MSE.append(mean_squared_error(y,yhat))\n",
    "names.append('kNN imputer (weighted)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the linear regressor imputation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.586\n",
      "MSE = 0.551\n"
     ]
    }
   ],
   "source": [
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=LinearRegression())\n",
    "pipe=Pipeline(steps=[('preproc',iterative_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('Linear regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the kNN regressor imputation method (uniform weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.544\n",
      "MSE = 0.607\n"
     ]
    }
   ],
   "source": [
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=KNeighborsRegressor(n_neighbors=7, weights='uniform'))\n",
    "pipe=Pipeline(steps=[('preproc',iterative_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('kNN regressor (uniform)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the kNN regressor imputation method (weighted average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.548\n",
      "MSE = 0.602\n"
     ]
    }
   ],
   "source": [
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=KNeighborsRegressor(n_neighbors=7, weights='distance'))\n",
    "pipe=Pipeline(steps=[('preproc',iterative_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('kNN regressor (weighted)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the R-squared and MSE values of the OLS on the dataset using the decision tree regressor imputation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.591\n",
      "MSE = 0.544\n"
     ]
    }
   ],
   "source": [
    "iterative_imputer=IterativeImputer(missing_values=np.nan, estimator=DecisionTreeRegressor())\n",
    "pipe=Pipeline(steps=[('preproc',iterative_imputer),('regr',linregr)])\n",
    "pipe.fit(X_miss,y)\n",
    "print(\"R2 = %1.3f\"%(r2_score(y,pipe.predict(X_miss))))\n",
    "print(\"MSE = %1.3f\"%(mean_squared_error(y,pipe.predict(X_miss))))\n",
    "R2.append(r2_score(y,linregr.predict(X)))\n",
    "MSE.append(mean_squared_error(y,linregr.predict(X)))\n",
    "names.append('Decision tree regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the obtained R-square and MSE values in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original data</th>\n",
       "      <th>Simple imputer (constant)</th>\n",
       "      <th>Simple imputer (mean)</th>\n",
       "      <th>Simple imputer (median)</th>\n",
       "      <th>Simple imputer (mode)</th>\n",
       "      <th>kNN imputer (uniform)</th>\n",
       "      <th>kNN imputer (weighted)</th>\n",
       "      <th>Linear regressor</th>\n",
       "      <th>kNN regressor (uniform)</th>\n",
       "      <th>kNN regressor (weighted)</th>\n",
       "      <th>Decision tree regressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.606233</td>\n",
       "      <td>0.477813</td>\n",
       "      <td>0.587068</td>\n",
       "      <td>0.579329</td>\n",
       "      <td>0.411745</td>\n",
       "      <td>0.584092</td>\n",
       "      <td>0.58540</td>\n",
       "      <td>0.606064</td>\n",
       "      <td>0.598484</td>\n",
       "      <td>0.599587</td>\n",
       "      <td>0.606010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.524321</td>\n",
       "      <td>0.695318</td>\n",
       "      <td>0.549840</td>\n",
       "      <td>0.560145</td>\n",
       "      <td>0.783291</td>\n",
       "      <td>0.553802</td>\n",
       "      <td>0.55206</td>\n",
       "      <td>0.524545</td>\n",
       "      <td>0.534638</td>\n",
       "      <td>0.533170</td>\n",
       "      <td>0.524618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Original data  Simple imputer (constant)  Simple imputer (mean)  \\\n",
       "R2        0.606233                   0.477813               0.587068   \n",
       "MSE       0.524321                   0.695318               0.549840   \n",
       "\n",
       "     Simple imputer (median)  Simple imputer (mode)  kNN imputer (uniform)  \\\n",
       "R2                  0.579329               0.411745               0.584092   \n",
       "MSE                 0.560145               0.783291               0.553802   \n",
       "\n",
       "     kNN imputer (weighted)  Linear regressor  kNN regressor (uniform)  \\\n",
       "R2                  0.58540          0.606064                 0.598484   \n",
       "MSE                 0.55206          0.524545                 0.534638   \n",
       "\n",
       "     kNN regressor (weighted)  Decision tree regressor  \n",
       "R2                   0.599587                 0.606010  \n",
       "MSE                  0.533170                 0.524618  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame(data=[R2,MSE],columns=names,index=['R2','MSE'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also create a bar chart for presenting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFxCAYAAABjrlPgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABAr0lEQVR4nO2deZhcVbW+3y8BDCKTEIdLCAkYRKaEGEAkV0SNggZwliiKICIKjtcBf15BQa56na5oFBEZVARBUUHDoMgsSBIIgQTxhkkCgoCXQeaE7/fHPpWcVKq7OqH2Od2n1/s89STn1On+9q6uWrXP2muQbYIgCIKhz4i6BxAEQRD0hjDoQRAEDSEMehAEQUMIgx4EQdAQwqAHQRA0hDDoQRAEDWGNuoQ33nhjjxs3ri75IAiCIcncuXPvsz2603O1GfRx48YxZ86cuuSDIAiGJJJu7+u5AblcJO0h6SZJiyQd3uH59SWdI+k6SQskHfBMBhwEQRCsOl0NuqSRwExgT2BrYIakrdsuOxRYaHsi8ErgG5LW6vFYgyAIgn4YyAp9J2CR7VtsPwmcDuzTdo2BdSUJeA7wT2BJT0caBEEQ9MtAfOibAHeUjhcDO7dd813gbOAuYF3gHbaf7skIgyAY1Dz11FMsXryYxx9/vO6hNIpRo0YxZswY1lxzzQH/zEAMujqca6/o9TpgHvAqYAvg95Ius/3QCr9IOhg4GGDs2LEDHmQQBIOXxYsXs+666zJu3DjSTXrwTLHN/fffz+LFixk/fvyAf24gLpfFwKal4zGklXiZA4CznFgE3Aps1WGQx9ueYnvK6NEdo26CIBhiPP7442y00UZhzHuIJDbaaKNVvusZiEGfDUyQNL7Y6NyX5F4p8zfg1cVAng+8GLhllUYSBMGQJYx571md17SrQbe9BDgMOB+4ETjD9gJJh0g6pLjsaODlkq4HLgQ+Y/u+VR5NEATBajBy5EgmTZrEtttuy1577cUDDzxQ95AGzMUXX8z06dN78rsGlFhkexYwq+3ccaX/3wW8ticjCoIWX1i/y/MPVjOOYJUYd/jvevr7bvvKG7pes/baazNv3jwA9t9/f2bOnMnnPve5no5jVVm6dCkjR46sVDNquQRB0Ch22WUX7rzzzpXOL126lPe+971su+22bLfddnzrW98CYO7cuUycOJFddtmFT33qU2y77bYAnHzyyRx22GHLfn769OlcfPHFAHzwgx9kypQpbLPNNhx55JHLrhk3bhxHHXUUU6dO5cwzz+SCCy5gl112YfLkybztbW/jX//6FwDnnXceW221FVOnTuWss87q2dzDoAdB0BiWLl3KhRdeyN57773Sc/PmzePOO+/khhtu4Prrr+eAA1JC+wEHHMCxxx7LlVdeOWCdY445hjlz5jB//nwuueQS5s+fv+y5UaNGcfnll/Oa17yGL33pS/zhD3/gmmuuYcqUKXzzm9/k8ccf5/3vfz/nnHMOl112GXffffczn3hBGPQgCIY8jz32GJMmTWKjjTbin//8J9OmTVvpms0335xbbrmFD3/4w5x33nmst956PPjggzzwwAPstttuALz73e8ekN4ZZ5zB5MmT2WGHHViwYAELFy5c9tw73vEOAK666ioWLlzIrrvuyqRJkzjllFO4/fbb+ctf/sL48eOZMGECkthvv/168AokwqAHQTDkafnQb7/9dp588klmzpzJ0qVLmTRpEpMmTeKII45gww035LrrruOVr3wlM2fO5KCDDsJ2n9Eka6yxBk8/vTw/shVCeOutt/L1r3+dCy+8kPnz5/OGN7xhhfDCddZZB0ix5NOmTWPevHnMmzePhQsX8qMf/QjIFxUUBj0Igsaw/vrrc+yxx/L1r3+dp59+epkxPeqoo7jvvvt4+umnectb3sLRRx/NNddcwwYbbMD666/P5ZdfDsCpp5667HeNGzeOefPm8fTTT3PHHXdw9dVXA/DQQw+xzjrrsP7663PPPfdw7rnndhzLy172Mq644goWLVoEwKOPPspf//pXttpqK2699VZuvvlmAE477bSezb+28rlBEAQ52GGHHZg4cSKnn376Ci6UO++8kwMOOGDZqvvLX/4yACeddBIHHnggz372s3nd61637Ppdd92V8ePHs91227HtttsyefJkACZOnMgOO+zANttsw+abb86uu+7acRyjR4/m5JNPZsaMGTzxxBMAfOlLX2LLLbfk+OOP5w1veAMbb7wxU6dO5YYbbujJ3GW3Z/FXw5QpUxz10IN+ibDFIcGNN97IS17ykrqH0RNuu+02pk+f3jMD+0zp9NpKmmt7Sqfrw+USBEHQEMKgB0EQFIwbN27QrM5XhzDoQRAEDSEMehAEQUMIgx4EQdAQwqAHQRA0hDDoQRAMeSStEHO+ZMkSRo8evaws7T333MP06dOZOHEiW2+9Na9//euBFKa49tprL8sonTRpEj/+8Y9rmUMviMSiIAh6S7f8gVX+fd3zDdZZZx1uuOEGHnvsMdZee21+//vfs8kmmyx7/ogjjmDatGl89KMfBVihmNYWW2yxrPTuUCdW6EEQNII999yT3/0u1WI/7bTTmDFjxrLn/v73vzNmzJhlx9tvv33l46uCMOhBEDSCfffdl9NPP53HH3+c+fPns/POOy977tBDD+V973sfu+++O8cccwx33bW8LfLNN9+8gsvlsssuq2P4PSFcLkEQNILtt9+e2267jdNOO22Zj7zF6173Om655RbOO+88zj33XHbYYYdlCUTDzuUiaQ9JN0laJOnwDs9/StK84nGDpKWSntv74QZBEPTN3nvvzSc/+ckV3C0tnvvc5/LOd76Tn/zkJ+y4445ceumlNYwwL10NuqSRwExgT2BrYIakrcvX2P6a7Um2JwGfBS6x/c8M4w2CIOiTAw88kCOOOILttttuhfN//OMfefTRRwF4+OGHufnmmxk7dmwdQ8zKQFboOwGLbN9i+0ngdGCffq6fAfSuwG8QBMEAGTNmzLJIljJz585lypQpbL/99uyyyy4cdNBB7LjjjsDKPvRjjz226mH3jK7lcyW9FdjD9kHF8buBnW0f1uHaZwOLgRd1WqFLOhg4GGDs2LEvvf3225/5DILmEuVzhwRNKp872FjV8rkD2RTt1Cupr2+BvYAr+nK32D4eOB5SPfQBaA8++jMyYWCCIKiRgbhcFgOblo7HAHf1ce2+hLslCIKgFgZi0GcDEySNl7QWyWif3X6RpPWB3YDf9HaIQRAEwUDo6nKxvUTSYcD5wEjgRNsLJB1SPH9ccembgAtsP5JttEEQDEpsZ+tkP1xZnfagA0ossj0LmNV27ri245OBk1d5BEEQDGlGjRrF/fffz0YbbRRGvUfY5v7772fUqFGr9HORKRoEwTNizJgxLF68mHvvvbfuoTSKUaNGrVB/ZiCEQQ+C4Bmx5pprMn78+LqHERDFuYIgCBpDGPQgCIKGEAY9CIKgIYRBD4IgaAhh0IMgCBpCGPQgCIKGEAY9CIKgIYRBD4IgaAhh0IMgCBpCGPQgCIKGEAY9CIKgIYRBD4IgaAhh0IMgCBpCGPQgCIKGEAY9CIKgIQzIoEvaQ9JNkhZJOryPa14paZ6kBZIu6e0wgyAIgm50bXAhaSQwE5gGLAZmSzrb9sLSNRsA3wP2sP03Sc/LNN4gCIKgDwbSsWgnYJHtWwAknQ7sAywsXfNO4CzbfwOw/Y9nOrBxh/+uz+du+8obnumvD4JhR3ymqqO/1xryvd4DcblsAtxROl5cnCuzJbChpIslzZX0nl4NMAiCIBgYA1mhd2rj7Q6/56XAq4G1gSslXWX7ryv8Iulg4GCAsWPHrvpogyAYctS1Wu2m3cS7koGs0BcDm5aOxwB3dbjmPNuP2L4PuBSY2P6LbB9ve4rtKaNHj17dMQdBEAQdGIhBnw1MkDRe0lrAvsDZbdf8Bvh3SWtIejawM3Bjb4caBEEQ9EdXl4vtJZIOA84HRgIn2l4g6ZDi+eNs3yjpPGA+8DRwgu0bcg68iQy328PhSJ3uh6D5DMSHju1ZwKy2c8e1HX8N+FrvhhYE+QjDGjSRARn0oNmEcQuCZhCp/0EQBA0hDHoQBEFDCIMeBEHQEMKgB0EQNITYFA2684X1+3nuwerGEQRBv8QKPQiCoCHECj0IOlHXXUl/urm1gyFPGPShQnzQgyDoQrhcgiAIGkIY9CAIgoYQBj0IgqAhhA89CIJ6qWt/qIH7UrFCD4IgaAixQg+CoJGr1UFNprDYoWnQ480XBEGwEuFyCYIgaAgDMuiS9pB0k6RFkg7v8PwrJT0oaV7xOKL3Qw2CIAj6o6vLRdJIYCYwDVgMzJZ0tu2FbZdeZnt6hjEGQRAEA2AgK/SdgEW2b7H9JHA6sE/eYQVBEASrykAM+ibAHaXjxcW5dnaRdJ2kcyVt05PRBUEQBANmIFEu6nDObcfXAJvZ/pek1wO/Bias9Iukg4GDAcaOHbtqIw2CIAj6ZSAr9MXApqXjMcBd5QtsP2T7X8X/ZwFrStq4/RfZPt72FNtTRo8e/QyGHQRBELQzEIM+G5ggabyktYB9gbPLF0h6gSQV/9+p+L3393qwQRAEQd90dbnYXiLpMOB8YCRwou0Fkg4pnj8OeCvwQUlLgMeAfW23u2WCIAiCjAwoU7Rwo8xqO3dc6f/fBb7b26EFQRAEq0JkigZBEDSEoVnLJSPjDv9dv8/fNqqigQRBEKwisUIPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhDKjBhaQ9gG+TeoqeYPsrfVy3I3AV8A7bv+jZKIPG0l9DkWgmEgSrRtcVuqSRwExgT2BrYIakrfu47qukZtJBEARBxQzE5bITsMj2LbafBE4H9ulw3YeBXwL/6OH4giAIggEyEIO+CXBH6XhxcW4ZkjYB3gQc198vknSwpDmS5tx7772rOtYgCIKgHwZi0NXhnNuO/wf4jO2l/f0i28fbnmJ7yujRowc4xCAIgmAgDGRTdDGwael4DHBX2zVTgNMlAWwMvF7SEtu/7sUggyAIgu4MxKDPBiZIGg/cCewLvLN8ge3xrf9LOhn4bRjzIAiCaulq0G0vkXQYKXplJHCi7QWSDime79dvHgRBEFTDgOLQbc8CZrWd62jIbb/3mQ8rCIIgWFUiUzQIgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCGHQgyAIGkIY9CAIgoYQBj0IgqAhDMigS9pD0k2SFkk6vMPz+0iaL2mepDmSpvZ+qEEQBEF/dG1BJ2kkMBOYBiwGZks62/bC0mUXAmfbtqTtgTOArXIMOAiCIOjMQFboOwGLbN9i+0ngdGCf8gW2/2XbxeE6gAmCIAgqZSAGfRPgjtLx4uLcCkh6k6S/AL8DDuzN8IIgCIKBMhCDrg7nVlqB2/6V7a2ANwJHd/xF0sGFj33Ovffeu0oDDYIgCPpnIAZ9MbBp6XgMcFdfF9u+FNhC0sYdnjve9hTbU0aPHr3Kgw2CIAj6ZiAGfTYwQdJ4SWsB+wJnly+Q9CJJKv4/GVgLuL/Xgw2CIAj6pmuUi+0lkg4DzgdGAifaXiDpkOL544C3AO+R9BTwGPCO0iZpEARBUAFdDTqA7VnArLZzx5X+/1Xgq70dWhAEQbAqRKZoEARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BAGZNAl7SHpJkmLJB3e4fl3SZpfPP4kaWLvhxoEQRD0R1eDLmkkMBPYE9gamCFp67bLbgV2s709cDRwfK8HGgRBEPTPQFboOwGLbN9i+0ngdGCf8gW2/2T7/4rDq4AxvR1mEARB0I2BGPRNgDtKx4uLc33xPuDcTk9IOljSHElz7r333oGPMgiCIOjKQAy6Opxzxwul3UkG/TOdnrd9vO0ptqeMHj164KMMgiAIurLGAK5ZDGxaOh4D3NV+kaTtgROAPW3f35vhBUEQBANlICv02cAESeMlrQXsC5xdvkDSWOAs4N22/9r7YQZBEATd6LpCt71E0mHA+cBI4ETbCyQdUjx/HHAEsBHwPUkAS2xPyTfsIAiCoJ2BuFywPQuY1XbuuNL/DwIO6u3QgiAIglUhMkWDIAgaQhj0IAiChhAGPQiCoCGEQQ+CIGgIYdCDIAgaQhj0IAiChhAGPQiCoCGEQQ+CIGgIYdCDIAgaQhj0IAiChhAGPQiCoCGEQQ+CIGgIYdCDIAgaQhj0IAiChhAGPQiCoCGEQQ+CIGgIYdCDIAgawoAMuqQ9JN0kaZGkwzs8v5WkKyU9IemTvR9mEARB0I2uLegkjQRmAtOAxcBsSWfbXli67J/AR4A35hhkEARB0J2BrNB3AhbZvsX2k8DpwD7lC2z/w/Zs4KkMYwyCIAgGwEAM+ibAHaXjxcW5IAiCYBAxEIOuDue8OmKSDpY0R9Kce++9d3V+RRAEQdAHAzHoi4FNS8djgLtWR8z28ban2J4yevTo1fkVQRAEQR8MxKDPBiZIGi9pLWBf4Oy8wwqCIAhWla5RLraXSDoMOB8YCZxoe4GkQ4rnj5P0AmAOsB7wtKSPAVvbfijf0IMgCIIyXQ06gO1ZwKy2c8eV/n83yRUTBEEQ1ERkigZBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNIQx6EARBQwiDHgRB0BDCoAdBEDSEMOhBEAQNYUAGXdIekm6StEjS4R2el6Rji+fnS5rc+6EGQRAE/dHVoEsaCcwE9gS2BmZI2rrtsj2BCcXjYOD7PR5nEARB0IWBrNB3AhbZvsX2k8DpwD5t1+wD/NiJq4ANJL2wx2MNgiAI+kG2+79Aeiuwh+2DiuN3AzvbPqx0zW+Br9i+vDi+EPiM7Tltv+tg0goe4MXATas57o2B+1bzZ58pdWnHnIeH9nDTrVN7qM55M9ujOz2xxgB+WB3OtX8LDOQabB8PHD8Azf4HJM2xPeWZ/p6hpB1zHh7aw023Tu0mznkgLpfFwKal4zHAXatxTRAEQZCRgRj02cAESeMlrQXsC5zdds3ZwHuKaJeXAQ/a/nuPxxoEQRD0Q1eXi+0lkg4DzgdGAifaXiDpkOL544BZwOuBRcCjwAH5hgz0wG0zBLVjzsNDe7jp1qnduDl33RQNgiAIhgaRKRoEQdAQwqAHQRA0hDDoQTDMkDRC0svrHkfQe4aUD13S84BRrWPbf8usN4YU1fPvwL8BjwE3AL8DzrX9dCbdUcD0Trq2F+TQLGnvAuxXaL+QFef8U9sPZtSewspz/oPtf+bS7DCGdYDHbS+tSO95wK6sOOc5ud5bJd0rbe+SU6MP3Vo+UyX9DUu6t+XWKzRHAPNtb5tdaygYdEl7A98g/SH+AWwG3Gh7m4yaJwGbAL8F5hS6o4Atgd2BlwKH2760x7pfAPYCLgbmdtAdBfyH7fm91C20zyXlD/yGznPeC/im7faw1Weq+17gI8CtrDznXUkf+M/n+AIvPmz7Au8CdgSeAJ4F3EuK3jre9v9m0N0dOBx4LnAtK855C+AXwDdsP9Rr7UL/i8B84CxXZARq/EytDxwKzADWIv1tRwHPB64Cvmf7ol5qdhjDqcBnsy9Ch4hBvw54FWm1tkPxYZhh++AuP/pMNLe1fUM/z68FjLW9qMe6b7D9u36ef16hO6eva56B9sa2+01HHsg1q6F7KCkc9rE+np8EbGT7wl7qFr/7EuAPpC+xG1orNknPJRmZdwK/sv3THut+DfhOpw+4pDVId2gjbf+yl7oljYeBdYClpNWqANteL4deoVnXZ+r3wI+Bc2w/0PbcS4F3A9fb/lEvddt0/khaMFwNPNI6b3vvnuoMEYM+x/aUwrDvYPtpSVfb3qkC7Y/a/na3c8HQRNKatp96ptcEQX9I2q3TeduX9FRniBj0PwBvBL5MKmrzD2BH29k3diRdY3ty27lrbe+QWXdL4FMk99KyBDDbr8qpW2i/Gfgq8DzSyi376q3Q3ZJUevn5treVtD2wt+0v5dQt6W9IKmFRfr2vyaT1if6et/3NHLptY9gbeEVxeLHt3+bWLHSnA0ez/L2d9f3VrT9Drr9xh3E8n7RKB7ja9j96rjFEDPo6pNvCESRf5/qkDbpsm2WSZpBut6cCl5WeWhdYavs1ubQL/euA40g+5WUbdLbn5tQttBcBe9m+MbdWm+4lpC+xH7S+MCXdUMlmknQ08F7gZpYXlnOuL1BJRxb/fTHpQ97al9gLuLRV3TQXkr5S6J5anJoBzLW9UgObDNqLgDeT3BzZDZCkln98FDAFuI70JbI98GfbUysYw9uBr5H2xkTaFP6U7V/0VMj2oH8AXx3IuR5rbga8ErgS2K30mAysUcGc59b4el9Rk+7s4t9rS+fmVaR9E7BWDXO+AFi3dLwucF4FuvOBEaXjkaRIjCrmfFFZu8LX+nRgu9LxtsDJFWlfBzyvdDwauK7XOgMpnzsYmAZ8pu3cnh3O9QzbtwO3A5WHdhWcI+lDwK9IkRetcVURwjdH0s+BX7dpn5VZ9z5JW1CskIta/FUVebsB2IDkzquSscCTpeMngXEVaW8AtN5P61ekCfBpYFZxR1Z+f+V2M21l+/qS3g3FhnsVjPCKLpb7yZAHNKgNuqQPAh8CNpdUDtNbF7iiojHU4k8G9i/+/VTpnIHNM+sCrEcqsvbaNu3cBv1QUtGirSTdSQpj3C+zZosvA9dKuoEVjUxPoxA68BPgakm/Ir3GbyJFZOSmNd+LSO/pVwCfrUAX4BjgXyQXyFoVaQLcKOkE4Kek13o/oCq34nmSzgdOK47fQQqL7SmD2odexI9uSHrzlX17D1e0Uq3NnzycKfZMRth+uELNBcAPgOuBZckm7nEUQh/ak0k+VUj+82tzaxa6LyT50UXyJd9dkW5dDS1GAR9k+UbwpcD3bT9ekf6bSXtyIv2df9VzjcFs0NupOlO00LzC9q65dfrQ3pbUmLs85+yrt+KN/z5gmzbtAzPpDYaIj0tsdwwtq0B7KjDB9kmSRgPPsX1rZs1dSfsTj0jaj7Q39O3C1ZiVYkP2j7YvyK3VQXttUqz76ra/XF3dZRnIkl5M2gw/1z0Ohx0StVwk7SXpf0m34JcAtwHnViQ/R9LPJc2Q9ObWI7doEQXxneKxO/DfQO7b/xY/AV4AvI70eo8Bcq6W1y0eU0grqE2KxyGkL7QqmCvpy5J2kTS59cgtWvydP8Nyd8eaJJdAbr4PPCppIsmtdzvVuHogudbOk/SYpIckPSwpS0ZsmSJMcx5wXnE8SVJPs5774VLgWZI2ISWyHQCc3GuRIbFCryNTtKR9UofTzrVaLeleD0wkRXxMLGJYT7C9V07dQvva4nWeb3t7SWsC5ztzDLykC4C3tFwtktYFzrS9R07dQqtT6rcrmPM8YAfgGi8P1Zxve/vMutfYnizpCOBO2z/qlHORQXcEsIvtSvbA2rTnkuzIxVW+1oVO6/X+MLC27f/Okc8yqDdFSzxl+36lKnEjbF8k6atVCNvO3X2pLx5zyohdImk9UvRFFRuiAK3bwAcKt8/dVBN5UUvEh6SRwNm2v5VbqwNP2rakVmTPOhXpPizps6SNwVcUr8GauUWL9/TXqSd6bIntB6VOPe2zI6XCd+8iuTMhg/0dKgb9AUnPId22nCrpH8CSKoSr9ieXmCNpA+CHpOSif5HqQFTB8UXW5OdJCS/PAY6oQLcc8QEpO/iU3KKFX3NvoA6DfoakHwAbSHo/cCBwQgW67yAlzr3P9t2SxpISX6rgAklvocLCYAU3SHonMFLSBFJBuD9VpP0xklvtV04tPDcnxeP3lKHiclkHeJy0O9zKFD3V9v0VaJ8J/IX05j+q0L/R9kdza5fGMA5YzxkqLA42ShEfBi6rMOLjGNL76uesWDwpe1q4pGmkEFGRXFu/r0CzvEm3JbAVGTbp+tCuvDBYofts4HMsD8c9Hzja9hN9/1SWcYwgbXz3fN9gSBj0OqnRn9z68trc9lHFCuoFtrOt0iXtZ/unfUWdVBRtMpEUVtYy6Nfl1ix06/Khf9X2Z7qdy6A7l/TFuSGphOwc4FHb78qpWyeS3mb7zG7nMmn/jLTJv5R0x70+qRR1T++KBnWUS2v3u69HRcNo9yevTzX+5O+R/IwziuOHgZmZNVv+23X7eGRF0kdJtUU2JiVy/bTYRMqO7d07PLIXQiNlQbezZwW6sv0oqabKd2y/ieRWrARJe0v6evGYXpFsp8SpqpKpti5W5G8kJRSNJZXt7SmD2odue10ASUeRNuZ+wnK3S3YDU9DyJ/8ny/3Jn69Ad+diV/xaANv/p1QvOhu2f1D8+8WcOv3wPtK8H4G0UiXV0vlObmGlJLYjWZ50cglwlDN1aFL9WdCdNulGVqDbqTDYRyVNdabCYJL2BF4PbCLp2NJT61HRXhywZnF3/0bgu7afam2E95JBbdBLvM72zqXj70v6Myk2OzcX2v4/0obs5gCSxleg+1QRedCKfhhNKYMxB21v9pWw/ZGc+qQv63Lrt6XFuSo4kVTP5e3F8buBk0gr2Bz8jJRLUVcW9MeoYJOuD14PTPLyZiKnkLo25ar0eBfJpbQ3yd3R4mHg45k02/kBKX/mOuBSSZsBw9OHLulPJHfD6SQDNwM41PXVQ59r+6WZdd9FikSYTIr0eCvwnzn9fZJa9WN2JSX0/Lw4fhup+mPWN3/hu9+fVJAM0mrmZNv/k1O30J5ne1K3c5m0R5LaoZXrsGfPgi6012ndEVVFcUfyytYXl1J3qIsriL0fVI1KJK1hu6d3CENlhf5O4NvFw6Rb0nfmFJS0FcmnuL5WzAxdj1L4Yi5sn1psXL2atEp9ozPXk7F9CoBSj8/dW29+SceRyrxmxfY3JV3M8noXB1QV5QI8Vtz2Xw7LUuM7tsTrJZIOA74A3MPyOzCTanXn1N0F+BHJhTi22Iz+gO0P5dQtqKsw2E5KPXvbG2tkz+9QSgz8L+DfbO8paWvSHllP294NiRV6HUjah7RC3JvlzQcg3aadbjt7/Koq7KDTpnsTKZuvtYLaELjK9osr0K5rzhNJqe+tMrL/B+yfO1RUqfjbzlWE4Lbp/pl013e2K2omImlX21dIehapOXalhcEk/YXkYmlvGlNF+PO5JBfe55wyv9cgZYFv10udobJCrxzbvwF+I2kX21dWra8+OuiQUpdz8xWWr6AgNfb4Qm7ROuas5f1hn1N80NYDyBEj3Ad3AFk2Xrth+w6tmDW5tK9re8SxwEuBKws3ZlV1VFo8aLuqGlDtbGz7DKXsXGwvkdTz1zsMenfepFRa9TFSUZ+JwMfc4y7wHXg7sIXtJ7te2WOcqv6dC7Q2og+vYgVFPXM+gOTK+w4wuSpDXor1vwW4WNLvqLbZwx2SXg64iJ76CPlrgz+lVBupPdoEyLfpruVF1i6S9DVSXf/ya11FT9FHJG3E8iCHl5HhizwMendea/vTkt4ELCZtEF5E/op4dXXQaSU1vYZSUpOknXImNRXUMecbJd0GjG4LH2z5V3P5sltht38rHmtRbbOHQ0hfZJuQ3tcXkKog5mQ66X31KlaMNsnNN9qOy7XYq7rr/QTpjmQLSVeQWtC9tdcig9qH3lfGYouKMhcX2N5G0g+BX9o+T9J1tidm1p0C/IZk5KrsoIOk75M26F5l+yWFX/sC2zt2+dFnqlvLnCW9gJQGvpKOK6gPXjVFVM0ptqvqBtWuP7GqDODBQPF6f4R0F/hi0mLhphwRN4N9hV5V8lB/nFNspjwGfKiIB6+iw8kppNZ3K3TQqYjKk5oKaplz4U7K+gXdF5LOYfl+QYsHSXHTP3CGbjpO9VtGS1qrSveWpE/b/m/goE5JNbnzHPpYID5ICsmdl0u3eL33carmuSCXDgxyg15jxmJ5DIcXGYsPFX+YR4B9KpC+z3a/iT4ZqTypqaDyOUs6w/bblerPl41MbpdLi1tIt9/lXpP3AFuSKm32PD284DbgCqUGD+ViZDnvels++jkZNfpjSvE4pzh+AzAbOETSmcWXTS6ukPRdMhd/G9Qulxaqr4RtS//lpPot5VC6rN1dJH2T5HY4m4o3cOpIaip0K5+zpBfa/nuRubcSuV0uki61/YpO51ruvky6R3Y6PxgWUblQatL8Ftv/Ko6fA/yC1Jh7ru1s3bFUUfG3Qb1CL/ETUgnb11EqYVuFsKSfAFuQWle1woxM/nZdrU4mLyudq2QDp46kpoLK52z778W/dfnKR0sa28oMVaqquXHxXDZ3SJ2GW6lc7ydZeZGU+73d3kDlKWAz249JylpC1/buOX9/i6Fi0F9k+22FH+oUpVKU51ekPYVUKa3SW5mq3gD9cA9wGek9srakybnvDuqcc5EN/FVSlUdRUY1u4D+AyyXdXGiOJ+3VrEPG5h51+O5LnAkcR2rkkTv2vczPgKsk/aY43gs4rXitF+YUrsp/P1RcLlfb3knSpaQKdXcDV1eUsnsm8JHWSq4Cvf2An7koXNTh+S2AF7ZS1DONoWOCT64V1CCZ8yJgr4ruRNq1n0VqMCHgL5mNaUvz26zsu78bWJvUTCWX776SWkj9aL+U5aUlLrddiT+/WIR28t9vReqb2xP//VBZodfVEg3S7e9CSVdTTSjdRqQszbmkWN17SfsGLyJlbN5Hvqp0LapO8BkMc76nSmMu6VW2/6gV6wRBKqeL7bMyD2GHNt/9OWXffWbtcyR9iFSErfyZylJlUtJ6th9SKgJ2a/FoPffcXLptbERKXGv5748k+e9fQXrP98SgD4kVep1I2q3TeduXZNQcSfIb7wq8kBQyeSOpRVj2KnySfgl80HZlCT6DYM7fBl4A/JoVjUwWwyrpi7aPLDIn23HuDX9JN5LKUpd99+fZ3loZutG3ad/a4bRz3XFL+q3t6YWuKdxprX8rutO/EZjYWiQVd2XzijyPnr3eQ8KgF5N/CytvohxVkf7zSYWEILl6Ks/erJI6k5rqoi7DWheSXk/yY6/guwcuBt7vCkoWDyckfZ4UTVP2359NymI93j1q/TdUDPp5FBsIrFglrT2lN4f220nd0C8mvfH/HfiU7V/k1q6L4pb7B7Ql+OS8KxmuqI+yqrZ7Wla1D+3KffeF7ns6na8gFLjV7Wy87aNVQZ/eNv3s/vuhYtCzlvXson0dMK21Ki+SbP7gzKn/dSLpEtsdXU1NpVihd8pezO36qKSsagfdZ5Pqi2xm+/2SJgAvtv3bnLqFdrml4ChSeOw1tnte26RNt5aSFiX9qcAEp+J3o0kVPju5n1abobIp+idJ29m+vgbtEW0ulvvJ3Fxb0gjgrbbPyKnTD3MlfZlqE3zqnnPZkI0i3R7fVYFuJWVVO3AS6Y53l+J4MSmcMLtBt71C42+lfq4/ya1LfSUtWpugU0i1XE4C1iQV+Nu1lzpDxaBPBd5bbGo8QXVp2QDnFRlm5fCurDWVbT+t1MmmLuNWR4JPrXO2/cvysaTTgD9UIF1JWdUObGH7HZJmABTJNVX1b23nUWBCBTp1lbSAtEDYAbgGwPZdknpeq2qoGPQ96xK2/akitKzl+zre9q+6/Fgv+L2kT7Jy7YfsIVY1JvjUNucOTCBlFubmP6igrGoHnpS0NsuN2xaU7sZy0pbUNILUv7aKL/JjSaGSz5N0DEVJiwp0AZ60bRVFyYpkpp4zqH3obfGjK1HFB13SeODvrQ2j4kPwfNu3ZdatNLSr0Kw1waeOOZe0H2ZFH/rdwGfbV+6ZtNcgc1nVDprTSMZsa1It9F2B99q+uALt8v7MEuB224tz6xbaW7G8pMWFVeUeFAuVCcA0Uk/VA0mfte/0+4OrqjPIDXqn+NEWVX3Q5wAvL8WPrgVcUdVGSpVI+ijpjdZvgo/t/61tkA1D0mXApaQyC1fYfrgCzRGk1emFJLeaSD1j78usK3cxOAO55hnoH0V6nf9k+5Fu1/dQV8AYUkTRa0mv9/m2f99zrcFs0AcDkubZntR2rooGF60ohLG2D64qCqHOBJ865ixpXH93W8WHcZNcK0hJm5Pcef9OMq5PAJfZ/ngOvZLuSlUecyPpYuCXwG/K76VikTQV2B+4yPbJmfQPLHR2ITV7vwy41Kl/cFZUUbmDIWHQtbwnYJkHSbdqSzJr/x74ju2zi+N9SLVdXp1Z9+ekVfJ7bG9buHqubP9yaRJ1zFmpVs8IUsJH+13J7qTb8yNzrKZKY3gh6Q7o3wvNv9neI5deofl50pd1ZfsVSmWwD6SIBQceIL3WI0lun5nO2GiiNI4XkMpbfBLY0Hb2RjqSZgIn256dVWeIGPSrSLW555NuV7YDriPVRzjE9gUZtbcATgX+rTi1GHi37ZtzaRa6c2xPKacFV3FnUCd1zblI5nkXy+9KHiXdlcwCfpEz4UapyuJ9pEqAl5HSwbNHXtS5X1Hor0mqk/SY7Qcq0jyBtGfQqiR6OSn+PeuisNBeSGpacjvpCzRLpN5QiXK5DXif7QWw7AP4KeBoUgfvbAa9MNwvUyqGryp8nAW1RSHUSC1ztr0Q+FxunT44luQGmEEKa7ukcIdkXTDYHp/z9w9A/ymgkgqmJTYi3Q08APyT1CEruzEvqCRSb6is0Dv5sefZntTpuR5p1h3x8VqSkSlHIRxgu1Pnk17q1pbgU9ecBwPFguEAkhtgjO2RNQ+psUh6CalZzseBkbbH1DyknjFUDPrPSd+opxen3kG6XXs3qSZCzyNOBkPER5FwUlkUQkm38g2zknYtc64LSd8grdCfA1xJcgVcZvuWWgfWQCRNJ+1TvALYkOL1tn1irQPrIUPFoK9NqgS3rLAN8D3gceDZLmoMZ9CtM+LjwvaN107nMmlXvmFW6NYy51ZYme07cur0of02UqTFPRVq1jnfkaSQvdfUoD2TIkTUdhVlHSpnSBj04UQRCfBs4CLglSyPvV+P9EXykgrGUHW96sEw50q76AyCcMk6uwadTQosqKLEQe3x7yWNzUjFuf5QLFLX6PWe3KDeFJV0hu23S7qezpXwqqjlUjUfAD5GiqopF8N6CJhZxQBq2DCrfc6kXpM75g4rK/G1Yr+i33BJUlRVDqqeb5nHgeuLkODyHeBHMuldpNS0pd/4d+DkTPpIej9wMPBcUtP5MaR69D29+xzUK3RJL7T99+KbbSVcX6f27Ej6sHucFrwK2nUlNdU554Wk9PvbyBhW1qZZZ7hkJWF0fWjv3+m87SxNsQdD/LukecBOwJ9LIbnXu8dlkge1QYfafW51RnzU0gSg0K4lqanmOQ+rRUPd8y1Wx1sWh5XUryl0K49/L3T/bHvnVo6FUv2ea4ZdHLrtpZIelbR+VT63knadJV3LkTvLmgAA2Y0b9ZVWrW3Otm9XhwYEuXXromW4JT2P9FpXhqRXAqeQ7oYEbCppf9uX5tauKf4dUn7B/wPWViqM9iHgnF6LDHqDXlC1z61MLSVdXV8TAKgvwae2OauiBgSDBUl7k/pZ/hvwD2AzkrtnmwrkvwG81vZNxVi2JPUbqGWTtiIOB95Hauv4AZJb7YReiwwVg/674lEHrRZkh5bOGagkRbpEVU0AAL4AnEdaOZ1KkeBTkXaZKudcSQOCMnWGD5KyrF9Gaqe4g6TdSdmqVbBmy5gD2P5r4QppLMXd/k9JIao3df2B1WSoGPSfk3b/Ddycc7OonbpSpLViE4CRwEuoyPVj+wJJc1me4PPRKhJ86pwzFTUgKFPo/Zp6VqZP2b5f0ghJI2xfJOmrFWnPkfQjlt997Ufas8lGnXtxhf7epGbzawHjJU0CjrK9dy91BrVBLzYO/ou0Sr6dVBVvjFJD389VsZFSV8QH8PXS/6tuAtBK5vldh3M5qW3OwBmSfgBsUISYHUiGW+IO1BU++IBSuYHLgFMl/YP0mlfBB0l3vB8hLRguJSUKZqPOvbiCI0lRLhcX45knaVyvRQZ1lIukbwHrAh9vBeBLWo/0wX/M9kcrGENtZWyVynzuRFq1zrZ9d2a9wZDgU+mc27SnkbkBQQfNysMlC911SNnAI0jhfOsDp9q+P6duh3E8l+R2ml+B1hmku87K9+Lao1yKc/OHW5TLdGDLcgaXU0u6DwJ/AbIbdGqK+JB0EHAE8EfSh/w7ko5y3roTtSb41DTnlvZXbX+G9GFvP5eTWvrl2n6klLl4SnEnWklBMKVGF3uT7M884F5Jl9j+RGbpOvfibpD0TmBkcZf/EeBPPVexPWgfwF9X57kej+FPwNqkmFFIWV5XV6B7E7BR6XgjUrxuFXP+cE1/7zrnfE2Hc/Mr0p5KqioJqUn0+Ao03w/MJu1JQdp8vrCi+V5b/HsQ8MWKX+u1gG2Lx5pVaBa6zwaOKV7z2cCXgFG91hnsK/SFkt7jtsQSpdK2f6loDF+gnoiPxaQ2WS0eBqqKhniwU5JP+98hA5XPubjb+xCwuaTybf+6wBU5tQv9usIlD6XIXASw/b9FTHoVrKHUpentVFiHvq7492JD9mynDdms8x3sBv1Q4CylXoBzSX7VHUkr5jdVMQDXFPEB3An8WdJvSPPeB7ha0ieKcX0zo3ZdCT51zPlnwLmkTuyHl84/7My5BgWVh0sWPGH7yZb3sAhAqGpD7SjgfFLp69lKfVWraDxeS/y7K9yQHdQG3fadwM6SXkVKeBBpc+7CqsZQY8THzcWjRauRbfYPu+tL8Kl8zsUH7EFJ7b7y50h6jjOXSaaGcMmCSjIXO2H7TODM0vEtwFsqkK4z/r2S5MhBHeVSJ4Mh4mOwULzp5zd5zlpe0VOku5LxJP991szJIgt5AjCNdJdwIHCa7WMz644gZS4ui+oBTnAFBkHSf5N8yI+R3JkTgY/Z/mlm3RNJf+Ny/PtI29ldqOpckMy9dmOGQe8DpY5FHyNFfJSL4T8E/ND2dzPrTyH52zajdCflaqrhdUzwsX143z/VE93a5txhLJOBD9j+QAValYdL1omWt498E/BGUiu4i5y/GfizSG7cVqOcS4Hv2c5e1kLSR21/u9u5Z6wTBr1/VFNJV0k3kRphXw8s62vqCqrhSdqtdFhZgk+dc+5jPNfYnpxZY6XQyCrCJSXtStrwb315tuLfs5e0kLTA9jaSfgj80vZ5kq7LbdDbxlBZ/Huht9J7qRyT3isGtQ99kFBXxMe9ts/OrNER25e0Jfhk7UBforY5tzZeC0YAk0lNJ3IzDWg33nt2ONdrfkRaGc8FlmbWauccSX8huVw+pFTZMns5jzri34v8lXeS0v3L7+11gZ4nccUKvQuSyqvzZREftt+aWffVpGJJF1KqdGj7rJy6hXZ7gs9upLoTWRN8ap7zkaXDJaTQtl86U92gcrgkK35hrgtcYXu/HLol/T/b3jmnRhf9DYGHigiQdYB1nT8T+lqnQmQHAZvaPjJHtmab5mak/ZiVoqhI+1I9LbcQBn0VaUV8uMdFdTro/BTYCljAcveDbR/Y90/1TPsm4OUu0sAlbQT8yfaLM+vWNufSGNYrNHva67GDzvqkzvO1hEtK+gppf+QsVvzyvKbPH+qddl0dsa4n7VWcQqoFNTu3Qa+acLmsOlWVdJ3oHrenWgXqSmqqbc7FhuxJFCGSkh4EDrSdpQrgIAiXbK3Op5SHBbwqsy6k13ku8PLieDEpjDF3wbu64t8rI1boXagx4uOHwLdsL8yp04f2j4HtSHHgyxJ8gL9CvqSmmuc8HzjU9mXF8VRSBETuIlm1hEvWiaQ5tqdoxUJVlW6KNpVYoXenrpKuU4H9Jd1KuiWurIkv9SU11Tnnh1vGnCR6uaSsbpdCZ4U7kla4ZC49SfvZ/mnbJnB5PDkzkFvU0hGrrvj3KgmD3oUaIz72qEhnJWx/sSbp2uZMKjHwA1IquIF3ABcXBrYS33JLR9KO3a9cbVqZqJ2+nKu6XT+SlesjvbcC3dfa/nQR/74YeBspcTC7Qa8qTDQMehc6RHxkLekqaT3bD7GiD7tSqk7wGQxzBiYV/x7Zdv7lZPQtVx0uafsHxb8rfWlL+lgu3ZLGCNJm8Jupvj5SK83/9aRs3H+qkt7nQEVhouFD70LVER+Sfmt7euF2aPlWW1SV+FFpgs9gmHNdVB0u2WUsf7M9tgKdS22/IrdOB92vkDJTHyPdcW8A/LaK8M2qwkTDoHdB0oXAnrafLI7XAma5pt6EVSDpcttT6x5HlUjaAHgPMI4V70qyd7Mp9CsJl+wyhjtsb1qBzudJRvXnrFioqopwzcrj3wvdSsJEw6B3oa6IjzqpM8GnLiT9CbiKle9KTsmsu0K4JJA1XLLLWKpaod/a4XT2O7G64t8L7Ys6nLbtnrrywofendrK2NbIAaQEnzUpJfiQVhdNZVTOFPB+OBH4UFu45ElArv2Kh+m8+SlSn4Hs2B5fhU4H6op/x/buuTUgVuhBByRdX2NSUy1I+jjwL9KHu3xXktUNIOkK27t2O9ckJL25w+kHgett/yOjbm3x70Vm8JFAa+/gElI5jZ42vIgVeheqjvho055KauJ7UlHA6Dm2O92u9pqrJG1dU4JPXXN+Evga6W/dWuWYVGslJ4MiXLJi3gfsQgoZhNRv4CpgyyKCLFczlVri3wtOBG4gtd0DeDfpjqHTl9tqEyv0LlQd8VHSXdZr0vaWkv4NOLOKlZukG0nNsCtN8Kl5zjcDO1cUPlfW7eRbbdFzH+tgoMi+Psj2PcXx84Hvk5pGX2p720y604D/BLYGLqCIf7d9cQ69Nu15tid1O/dMiRV6d+oq6VpXr0moL8GnzjkvINXpqZSqfKuDjHEtY17wD2DLIi78qRyCNce/Azwmaarty4vx7EqK9OkpYdC7c6SkE6g+4qPyXpODIMGnrv6akJI95hUr5vLfOWvYYt3hkjVxmaTfsryv6FuBS4u/9wM5BG0/Lekw22dQ6g9cIR8ETil86QL+SYbs2DDo3akr4uOMwre6gaT3k3pN/jCz5s+A6aRIgJUSfMjvT65jzi1+XTyqZhYdwiUbzqGklXKrFdwppGQqAznvWH6v1MO18vh32/OAiUW+AcXCqeeED70LdUZ8aJj1moThN2dV0OZuMKLU+GGC7T8U8eEjcydV1RH/XnUxtFihd6e2iI/CmDXaoLVT9ZwlnWH77VpexrZ9PLmjmX5S3I1UGi5ZJ8V8DwaeS9p83wQ4jtQNLBs1xb/3Vwyt58QKvQtVR3x0Sfyw7fVy6NZJnXOW9ELbfy9WjCtRQTTTocAxJN/xsnDJhtevmUeqpfLnUjx49jvhuuLfqyRW6N2pNOLDdpMzUDtS55xt/734N6vh7odPAC+qOlyyZp6w/WSr0qGkNaimdG9d8e+V1WIPg94HgyDio9XsYCrpzX657Wsr1K4lwafOOddELeGSNXOJpP8HrF3smXwIOKcC3aeBl3SIf98ZuBTIZtCpqBZ7GPS+qTXiQ9IRpD96K5rmZEln2v5STt1Ce1mCDymbbU3SGy9rgk+dc66RWsIla+YzpCSi60ndmWYBJ1SgW3n8e4lKarGHD32QUvjud3BRF7tIWb7G9ksq0J5HkeBT8nFm745e55zrQtL+nc47c5XHuigSfObnygbtov09YCwrxr/fQcoE/23OJC9VVIs9VuiDl9tITYNbjQ6eRXXt7+pK8LmNiudcrIz7WtXYdu7Ii0Ya7r4oEnyukzTW9t8qlq8r/h3bh0v6KstrsT9CKsXdU8KgD16eABZI+j3J4EwDLpd0LGS/Ja8rwaeOOX+yw7mXAZ8m3ZJnYRCES9bJC0l/56tZMcFn75yixSJlDvBgKf79OWTcJ5P0Ktt/LEfYtLlaepqgGC6XQUpft+Itcq/s6kjwGQRz3g34POnO4L9sn5tRq9ZwyTopXueVsH1JZt1l8e+2t1BqcHFczrswSV+0faSkkzo8bdsH9lQvDHp36or4CKpB0utIhvxx4Bjb/VVADIYodcW/V8mIugcw2CkiPj4DfLY41Yr4yK07XdK1kv4p6SFJD0vKUv+hpPlwodX+yK5d6Ncx59lAqx75p4EHJU1uPXJqB5XzhIvewFBp/DuS/kupEFvreENJPY/eihV6F2qM+FhE2sC53sPkj1THnCVdTP+boo2rRz5cKZJ7HiBVt/wwKf59oe3PVaB9bct+lM71vI5PbIp2p66IjzuAG+oy5jUl+FQ+Z9uvrEorqJ264t8BRkp6lu0nYFlI7rN6LRIGvTt1RXx8Gpgl6RJWTDjpaXW2TtSY4FP5nCW9op+n7aJ5cwbdWsMl66DOObfFv1dVkrnMT4ELi81Rk+xIzzf5w+UyAGqK+LiA1LS4vfXdFyvQriXBp445K7VDa8ekWhtjbI/MpPvSDqeXhUva3jGHbp3UPWdJpwKfrSH+vaW/B/Aakh25wPb5vdaIFfoAcD1lbJ9r+7UVa7a4jXqSmiqfs+29ysdFRNPngL8Dh2XUnVvSLIdLHpIzXLJOBsGca4l/L3EjsKQVAy9pXfe4BnwY9D5Q/WVs/yDptbYvyKzTibqSmmqbs6RXkwyMSTHoVdyFDbtwyZrnnP3uti9UUQ34cLkMUoovlHVIxvUpKqyHXleCTx1zlvQG0or8QeBLtq/IpdWmOxsYDXwNuLL9edvXVDGOKhmOc25RVQx8GPQBUFPER1ABkp4mlTO9js4p+Flux4djuORwnHMLSX+2vXMrfLGIgb+m1+HP4XLpQtURH5K2sv2XvpJaqljFSJoOHA1sRnqPZF0p1zznrEWZ+mI4hksOxzmXuEQV1ICPFXoXqo74kHS87YOLEK92KlnFVJ3gM0jm/NLypl1xbi/bWRov1BUuWSfDcc4tirDJ91GKlgNO6PXnKwx6FySdC8yw/UBxvAHwU9vT6xxXTgrD+mrbT3e9uCFIugbY3/b1xfEMUouwntarLunVEi5ZJzWGiA6KmH+lOlDYvjebRhj0/pH0a2BHUtjisogPitKqvY74kLQjcIftu4vj9wBvAW4HvuAKusEXYzgaqCTBZ5DMeXPgF8C7SPsl7wGm234wt3ah3wqX3JAU/VFFS7ZaqWrOdca/SxJwJCkEVsVjKfAd20f1XC8Mev9UHfFRrBRf49Si6hXA6aS6E5NI/RDf2ku9PsZQaYLPYJhzMY4tgV+TShC80fZjFWhWHi5ZN3XOWRWWSC70Pk5qO3ewiwqtxeLh+8B5tr/VU70w6IMLSdfZnlj8fyZwr+0vFMfzbE+qYAxzbE/JrVPSq23OWrnBxPNIIYxPQL5GE3WFS9ZJnXOuK/5d0rXANNv3tZ0fTcoW3aHzT64eEeXShaojPkhFfNawvYSUdHBw6bmq/l5VJ/jUOee69kLOIYVL3g98Rm0NgyvMXqySWubcKf69HFGVOYpqzXZjXmjeK2nNTj/wTAiD3p3/odqSrqeRQpzuIzWUvQxA0otIK5sqOBT4tKSqEnxqm7Pr6wxUS7hkzdQ150dILsS3Fo8yBnJGUT25ms+tFuFy6UIdER+SXkaqO3GB7UeKc1uSOiU1MptuOM4Zqg+XHAwMpzlLWkqpbkz5KWCU7Z6u0sOgd6HqiI86GQxJTcONqsMlBwM1hIgOm/j3MOhdqDrio04GQ4LPcKPucMk6qHrOwynmPwx6F6qO+AiGH3WES9ZNnXNucsx/GPQuSPoK8McKIz5qYzAk+AwX6gqXrJO65zwcYv7DoHdBNZaxrZrBkuAzHJC0WX/P1xh9k4265jycYv7DoAfLGAxJTUHQa1RTieQ6iDj0PhimER+DIakpCHrNsIn5jw9p33yCZNC+0eG53MkIdTEYkpqCoKfYvgT6jn+vZ1R5CJdLsALDNcEnaD7DIeY/DHofRMRHEDSL4RDzHwa9DyLiIwiaR9Nj/sOg90FEfARBM6g7/r1KYlO0byLiIwiaQWPbRbYThqlvIuIjCBpAE5O0+iJcLv0QER9BEAwlwqAHQRA0hBF1DyAIgiDoDWHQgyAIGkIY9CAIgoYQBj0IgqAhhEEPgiBoCP8fBiVmXLlbBsgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "table=pd.DataFrame(data=np.array([R2,MSE]).T,columns=['R-squared','MSE'],index=names)\n",
    "table.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the simpler imputer with mean and median, respective the imputer with linear, kNN and decision tree regressor provides a very similar result, as obtained with the original data. The simple imputer with a constant value of 0 is the worst. For some random deletion, the simple regressor with the mode is also not performing well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/AML1-Cover.png\" width = 110, align = \"left\" style=\"margin:0px 20px\">\n",
    "\n",
    "<span style=\"color:blue\">**Note:**</span> This Jupyter Notebook is accompanying the book: <br> $\\qquad$ <b>Advanced Machine Learning Made Easy</b> <br> $\\qquad$ From Theory to Practice with NumPy and scikit-learn <br> $\\qquad$ <i> Volume 1: Generalized Linear Models</i><br>\n",
    "by Ferenc Farkas, Ph.D. \n",
    "\n",
    "If you find this Notebook useful, please support me by buying the book at [Leanpub](http://leanpub.com/AML1). <br>\n",
    "Copyright notice: This Jupyter Notebook is made available under the [MIT License](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch1-1-SimpleRegression.ipynb",
   "provenance": [
    {
     "file_id": "1CAvi5U76y6xIKJarmRS-iX0Jh70o2mGi",
     "timestamp": 1537170166740
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
